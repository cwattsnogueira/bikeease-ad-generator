{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwattsnogueira/bikeease-ad-generator/blob/main/GenAi_Inc_Unit6_Capstone01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXW-jTwQ-qKy"
      },
      "source": [
        "# Essentials and Applications of Generative AI: Incremental Capstone\n",
        "\n",
        "Carllos Watts-Nogueira\n",
        "\n",
        "Due: 13/Sep/2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4WtPrvu-sFt"
      },
      "source": [
        "**Overview**\n",
        "\n",
        "BikeEase has successfully implemented various AI-powered solutions for demand forecasting, customer review analysis, and image classification. As they continue to grow, they aim to automate certain tasks using Large Language Models (LLMs), particularly in marketing and advertising generation to attract more customers and increase engagement.\n",
        "\n",
        "To achieve this, BikeEase plans to develop a Generative AI-powered system that can automatically create engaging and persuasive advertisements based on bike specifications, discount offers, and promotional themes. This will enable them to generate high-quality marketing content without manual effort, saving time and ensuring brand consistency\n",
        "\n",
        "**Project Statement**\n",
        "\n",
        "Develop a Generative AI-powered advertisement generation system using LLMs and LangChain to create compelling promotional content for BikeEase’s rental services"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnls5Qo6IUZ9"
      },
      "source": [
        "# Version without (LangChain) --> TinyLlama/TinyLlama-1.1B-Chat-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv7z2Nl8-1j2",
        "outputId": "1d0658df-3707-401b-b1c5-9619e1a40aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.5 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "!pip -q install transformers accelerate langchain-community\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "8e2e3a846a0b468f843e5c1f334ba202",
            "f031c068063b418bb609978c92de801b",
            "b8c100fca4fb4f3eb316227b1a906694",
            "6fd10aaffdf44dfdbcb8d5e3c7d7cb50",
            "e451093ca8204a7fa5b281a662f11065",
            "c976a9dfe74b4f7fa231ec4410f9ed08",
            "a2fbd079f37441e5b99a067492734514",
            "11855fc45d12474eb2914bf55aa7cabc",
            "274c1f1dd08c436b98b2a13e23b11421",
            "15c7b2b91112477383ea7ea54d27ac96",
            "604fce77a5e045739b65f3e91e6f35b3",
            "9c7e058fb0294d76b58427128994e804",
            "d68b5dd676ac45639ba101cdefd3d115",
            "cf02eb9d52e74088b6a2ec9d23bf1ddb",
            "fe1f64dae68441b68b6cf2caf9e2c604",
            "7c77b1843dcc4c10b0b23fdb64da5b84",
            "f7433aa2d28d4e9c9a9429dc9aa14b10",
            "75e273722cc746e3accddf5b5e6dbfa2",
            "01e289a1844b45c6aca95f82e486e692",
            "0aff035ff6a0478391ae922472c30dcd",
            "7c52116c4e1a412a8d6f373d7f466372",
            "1ee90d84f19548f388035060ebf50818",
            "126f1f42a209416ba9a7ddcafe14d3ce",
            "a5c10270853a42238d8154bd43772693",
            "2248d47fee1e451c865c75cf87d0879a",
            "585a0a38707449d58f820a99c19114ce",
            "2b5a28b667d04da3919542a77d12c568",
            "be17bc39b24d484bb5b77719e292da6c",
            "a346ef387db54ed3903c1c21948c3d30",
            "9f80665a962d41799e6e2838706e6ee1",
            "b8b26a4a65b14dfaa17ce8238a3db875",
            "e45b92144d1d438584f7e192772a2a1b",
            "a94436efddba4c05b082dd11d1acc2d1",
            "453a04f35cc848d0a5ff34e346dac123",
            "cac32c99dc844ab795804cc0bd745a75",
            "574244cee65e4bddbe402dd9fe1ef91a",
            "82ef2f1fa87e4c98a95e1cbb5da81a51",
            "25adf8ddd956448fa6abbd6d78475522",
            "2bd26de0f1b143268eeb95ae26de9ec4",
            "c802950e50d3425caadec6529bbef6b0",
            "019cdaabae7343dc9d2c39788be932d2",
            "09eb2b98ac0e471eb69d95be477f68b3",
            "c4f8678a9b2341e5ae46a1cc4428c88c",
            "ae0a786e3b3b487fa3ac6da34f138f0c",
            "28ab51a4714b486a851266872e958910",
            "b2956af204524a27a9429e6b0effbaf5",
            "07e95885bf904ef089d318298a6a0945",
            "9dbdd3a40718469d9987cfe85307373f",
            "05e655f75ada4e78bac9dc6364c81cb0",
            "fbae7eb26b10436b84851b7d5fd38899",
            "1f0f2569cf0341cba597ad10be089548",
            "6279182a7a6f45f3837934b61d7cc3c8",
            "0a68f5a2dba2455b820940d741553853",
            "674dd3b99e4541f5acc15cb110159504",
            "28851bb92e7f4642bb15968b7e5f754d",
            "e12fc5cc0e7c4de8babe63098ebbd332",
            "6f946f53b069478bbf756b6e48567a65",
            "ad09c77f40d24b17913a1c8b1b11295c",
            "3e2e03d8293548b9b7d2e402b562196c",
            "7d743937be62431980ea4cceab97312c",
            "7b1e71b8a2514140bc54c052690f3b5c",
            "4a45376162844be993cc2353924d493c",
            "85ff2dee6cc7480ab429da0b9317ef58",
            "2a0167cd732b441ab0b064e964b9c1c8",
            "0eb89d2530c34ef58f62ec9e78359709",
            "5eb86b6e26b24d2ba0e34659c12b0f06",
            "c0e1e3a3839d471d97d8b366a14b8a46",
            "bab1252740c34c6f9ea403d5c1678625",
            "3e9e0280b7c84e80992a3f3ee0b546d9",
            "67403e722e5047d8a495075a1a3107ec",
            "0b1c7db64ba142048afac52d9bf9d7bb",
            "ab823a7d4dc6417e95a075eec478a7f3",
            "90bd262eebb14aa88ad41533946925cb",
            "ea915818c75e4efaae965b65b9938082",
            "1f91378577ce497f96820fc314571974",
            "95decb6a6257422e91dac38393d78641",
            "4be17558278f48eba4e88ea9bf18a115"
          ]
        },
        "id": "DDIk0Ozj_nWW",
        "outputId": "6839812b-6486-4f3f-d846-45f6821b0ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e2e3a846a0b468f843e5c1f334ba202"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c7e058fb0294d76b58427128994e804"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "126f1f42a209416ba9a7ddcafe14d3ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "453a04f35cc848d0a5ff34e346dac123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28ab51a4714b486a851266872e958910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e12fc5cc0e7c4de8babe63098ebbd332"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0e1e3a3839d471d97d8b366a14b8a46"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Try using a GPU if available, else use a CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# Load model/tokenizer\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        ").to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "847n0EcmxpdC"
      },
      "outputs": [],
      "source": [
        "# Provide simple yet concise instructions so the model stays on track - you should change these to your own\n",
        "SYSTEM_MSG = (\n",
        "    \"You are an advertising specialist for BikeEase, a bike company. \"\n",
        "    \"Your task is to create an engaging and persuasive marketing advertisement.\"\n",
        "    \"Return ONLY these sections exactly once, in order, no extra text:\\n\"\n",
        "    \"[Header]\\n\"\n",
        "    \"[Subheader]\\n\"\n",
        "    \"[Body]\\n\"\n",
        "    \"[CTA]\\n\"\n",
        "    \"[Hashtag]\\n\"\n",
        "    \"[Footer]\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6hlyt8G0h9w"
      },
      "outputs": [],
      "source": [
        "# Define your chat here...\n",
        "def generate_ad(specs, discount, theme):\n",
        "    print(\"\\nBuilding the prompt for the model...\")\n",
        "    # Build the text prompt that will be fed to the model\n",
        "    # SYSTEM_MSG: sets the overall role from above (e.g., \"You are an advertising specialist for BikeEase\")\n",
        "    # specs, discount, theme: user-provided inputs\n",
        "    prompt = f\"\"\"{SYSTEM_MSG}\n",
        "\n",
        "    - Bike Specifications: {specs}\n",
        "    - Discount / Promotion: {discount}\n",
        "    - Campaign Theme: {theme}\n",
        "\n",
        "    Write the advertisement now.\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize the prompt by converting words into numeric IDs the model understands\n",
        "    # return_tensors=\"pt\" = output as PyTorch tensors\n",
        "    # .to(device) = move tensors to GPU if available, otherwise CPU\n",
        "    # inputs = tok(prompt, return_tensors=\"pt\").to(device)\n",
        "    inputs = tok(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    # The truncation=True argument is added to the tok() function.\n",
        "    # This is important because it tells the tokenizer to shorten the input text if it exceeds the maximum length the model can handle.\n",
        "    # This prevents errors that can occur when the input is too long.\n",
        "\n",
        "    print(\"Generating the ad... Please wait.\")\n",
        "    # Disable gradient tracking to save memory since we aren’t training\n",
        "    with torch.no_grad():\n",
        "        # Generate new text from the model based on the prompt\n",
        "        # THESE ARE ONLY PLACEHOLDERS - YOU NEED TO ADJUST THESE!\n",
        "        out = model.generate(\n",
        "            **inputs,                       # the tokenized prompt\n",
        "            max_new_tokens=512,             # Increased to allow for longer, more complete ads. #10 # cap on how many new words to generate.\n",
        "            do_sample=True,                 # enable sampling for variety # Enables sampling for more creative results. # enable sampling for variety\n",
        "            temperature=0.7,                # A good balance between creativity and coherence. #0.1 # randomness: lower = focused, higher = creative\n",
        "            top_p=0.95,                     # Nucleus sampling to consider a wider vocabulary. #0.5 # nucleus sampling: sample from top 90% of probable words\n",
        "            repetition_penalty=1.2,         # Slightly penalizes word repetition. #1.15 # discourage repeating the same phrase over and over\n",
        "            no_repeat_ngram_size=3,         # Prevents the repetition of 3-word sequences. #4 # block repeating any 4-word sequence\n",
        "            eos_token_id=tok.eos_token_id,  # stop if end-of-sequence token is reached\n",
        "            pad_token_id=tok.eos_token_id   # pad with EOS token if needed\n",
        "        )\n",
        "\n",
        "    # Slice out only the newly generated tokens (skip the original prompt part)\n",
        "    # gen_ids = out[0, inputs[\"input_ids\"].shape[1]:]\n",
        "\n",
        "    # Decode the token IDs back into readable text\n",
        "    # skip_special_tokens=True = remove tokens like <pad> or <eos>\n",
        "    # .strip() = clean up leading/trailing whitespace\n",
        "    # return tok.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Decode the generated tokens back into readable text.\n",
        "    # We skip special tokens and strip any extra whitespace.\n",
        "    generated_text = tok.decode(out[0, inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd02Tpvv6HUA",
        "outputId": "f073f43d-9edf-4d46-c5a7-91f1c3043777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BikeEase Ad Generation System ---\n",
            "Please provide the details for the new advertisement.\n",
            "Enter bike specifications (e.g., 'E-bikes with pedal assist; mountain & road bikes; helmets included'): E-bikes with pedal assist\n",
            "Enter discount or promo (e.g., '20% off weekend rentals'20% off weekend rentals\n",
            "Enter marketing theme (e.g., 'Summer mountain adventure'Summer mountain adventure\n",
            "\n",
            "Building the prompt for the model...\n",
            "Generating the ad... Please wait.\n",
            "\n",
            "--- Generated BikeEase Advertisement ---\n",
            "\n",
            "[Image or Graphic that prominently represents your product/service (optional)]\n",
            "BikeEase offers top quality e-bike rentals that make it easy to enjoy summer\n",
            "mountain adventures on two wheels. Our bikes come equipped with powerful pedal\n",
            "assistance systems designed specifically for hiking, biking and other outdoor\n",
            "activities. No matter what you're planning, our rental fleet includes options\n",
            "from beginner to advanced levels so you can find the perfect fit for your needs.\n",
            "With discounted rates during peak season, this is the time of year when our\n",
            "customers love trying new things. So why wait? Rent one today!  [Headline]: Join\n",
            "us on summer adventure. Discover peaceful tranquility with e-biking on the\n",
            "trails.  Summer is a great time to escape into nature. And who better to take\n",
            "care of your cycling needs than Bikeease, the experts at making mountain bikers\n",
            "happy since 1983? We offer everything you need to have a fun, safe, and healthy\n",
            "summer experience. Whether you’re looking for a more challenging route or just\n",
            "want to relax and unwind, we’ve got you covered. Sign up for a monthly\n",
            "membership plan or choose a specific date to join us. Take control of your\n",
            "adventure – let Bike Easy show you where the beauty lies. #ridethemountain\n",
            "#summersummeradventure #peacefultranquillity #outdoorslover  Join us on a\n",
            "journey like never before by signing up for our exclusive monthly ride program\n",
            "or reserve a spot on one of our scenic hikable routes around the valley. Find\n",
            "something for everyone. From gentle walks through pine forest to rugged climbs\n",
            "over rocky ridges, our trail network has something for all skill levels. Choose\n",
            "your preferred ride length and level of difficulty, then hit the road with us.\n",
            "We will provide you with full gear such as helmet, lock, water bottle, and food\n",
            "bag. Our staff will be there to help you navigate each stretch of trail, answer\n",
            "any questions you may have about the area, and guide you safely throughout every\n",
            "step of the way. Let Bike ease take care off your entire mountain biker\n",
            "experience. #hiketour #mountainbikeexperience #ecofriend\n",
            "\n",
            "--------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Define some user inputs here. You should modify these...\n",
        "# Collect user inputs and run the generation\n",
        "print(\"\\n--- BikeEase Ad Generation System ---\")\n",
        "print(\"Please provide the details for the new advertisement.\")\n",
        "specs_input = input(\"Enter bike specifications (e.g., 'E-bikes with pedal assist; mountain & road bikes; helmets included'): \")\n",
        "discount_input = input(\"Enter discount or promo (e.g., '20% off weekend rentals'\")\n",
        "theme_input = input(\"Enter marketing theme (e.g., 'Summer mountain adventure'\")\n",
        "\n",
        "# Call the function with the user's inputs.\n",
        "advertisement = generate_ad(specs_input, discount_input, theme_input)\n",
        "\n",
        "print(\"\\n--- Generated BikeEase Advertisement ---\\n\")\n",
        "# print(generate_ad(specs, discount, theme))\n",
        "# use textwrap to format the text for better readability in the console.\n",
        "import textwrap # Used to format the text output\n",
        "print(textwrap.fill(advertisement, width=80))\n",
        "print(\"\\n--------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version with (LangChain) --> TinyLlama/TinyLlama-1.1B-Chat-v1.0"
      ],
      "metadata": {
        "id": "qfdEUM4ISM4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers accelerate langchain langchain-community"
      ],
      "metadata": {
        "id": "FnKzgOZ_SSTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the Hugging Face Model\n",
        "\n",
        "I use `TinyLlama/TinyLlama-1.1B-Chat-v1.0`, a compact LLM suitable for local inference. The model is loaded with PyTorch and optimized for GPU if available."
      ],
      "metadata": {
        "id": "sU0LYImbSlEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        ").to(device).eval()"
      ],
      "metadata": {
        "id": "u2FHiF5sSsjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain Setup\n"
      ],
      "metadata": {
        "id": "7nOFovuRS3FT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define Prompt Flow with LangChain\n",
        "\n",
        "I use LangChain's `PromptTemplate` to define the ad structure and `LLMChain` to manage the generation process. This makes the pipeline modular and easier to tune."
      ],
      "metadata": {
        "id": "DSxW-JX0S8mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain.chains import LLMChain\n",
        "from transformers import pipeline\n",
        "\n",
        "# Define the structured prompt\n",
        "SYSTEM_MSG = (\n",
        "    \"You are an advertising specialist for BikeEase, a bike company.\\n\"\n",
        "    \"Your task is to create an engaging and persuasive marketing advertisement.\\n\"\n",
        "    \"Return ONLY these sections exactly once, in order:\\n\"\n",
        "    \"[Header]\\n[Subheader]\\n[Body]\\n[CTA]\\n[Hashtag]\\n[Footer]\"\n",
        ")\n",
        "\n",
        "template = PromptTemplate.from_template(\n",
        "    \"{system_msg}\\n\\n\"\n",
        "    \"- Bike Specifications: {specs}\\n\"\n",
        "    \"- Discount / Promotion: {discount}\\n\"\n",
        "    \"- Campaign Theme: {theme}\\n\\n\"\n",
        "    \"Write the advertisement now.\"\n",
        ")\n",
        "\n",
        "# Wrap the HF model in a LangChain-compatible pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if device == \"cuda\" else -1,\n",
        "    max_new_tokens=350, # + - 250\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.2\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "# Create the LangChain LLMChain\n",
        "ad_chain = LLMChain(llm=llm, prompt=template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COScn64iS696",
        "outputId": "ffb98124-e313-4d8e-efab-bb8dcb1b1a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input\n",
        "## Step 3: Collect User Inputs\n",
        "\n",
        "I ask the user to provide bike specifications, discount details, and a campaign theme. These will be passed into the LangChain prompt.\n",
        "\n"
      ],
      "metadata": {
        "id": "A7nH2gljTGH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specs_input = input(\"Enter bike specifications (e.g., 'E-bikes with pedal assist; mountain & road bikes; helmets included'): \")\n",
        "discount_input = input(\"Enter discount or promo (e.g., '20% off weekend rentals'): \")\n",
        "theme_input = input(\"Enter marketing theme (e.g., 'Summer mountain adventure'): \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYjNphsGTRJr",
        "outputId": "8365c0ef-bcf1-460a-8703-24ca0084cd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter bike specifications (e.g., 'E-bikes with pedal assist; mountain & road bikes; helmets included'): mountain & road bikes\n",
            "Enter discount or promo (e.g., '20% off weekend rentals'): 30% off monthly rentals\n",
            "Enter marketing theme (e.g., 'Summer mountain adventure'): Fall mountain advanture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Generate the Advertisement\n",
        "\n",
        "Here the code pass the inputs into the LangChain `LLMChain` to generate a structured ad. The output will follow the format defined in our prompt template."
      ],
      "metadata": {
        "id": "GIRZzf4cTa_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated system message with clearer instructions\n",
        "SYSTEM_MSG = (\n",
        "    \"You are a creative advertising copywriter for BikeEase, a bike rental company.\\n\"\n",
        "    \"Your task is to write ONE complete and persuasive advertisement using the format below:\\n\\n\"\n",
        "    \"[Header]: A bold, catchy title\\n\"\n",
        "    \"[Subheader]: A short supporting phrase\\n\"\n",
        "    \"[Body]: Describe the bike features, the discount, and the campaign theme\\n\"\n",
        "    \"[CTA]: A clear call to action\\n\"\n",
        "    \"[Hashtag]: A relevant hashtag\\n\"\n",
        "    \"[Footer]: A closing line that reinforces the brand\\n\\n\"\n",
        "    \"Use a friendly and adventurous tone. Keep the ad under 150 words.\\n\"\n",
        "    \"Do not repeat or generate multiple versions. End after the [Footer] section.\"\n",
        ")\n",
        "\n",
        "response = ad_chain.invoke({\n",
        "    \"system_msg\": SYSTEM_MSG,\n",
        "    \"specs\": specs_input,\n",
        "    \"discount\": discount_input,\n",
        "    \"theme\": theme_input\n",
        "})\n",
        "\n",
        "ad_text = response.get(\"text\", \"\")\n",
        "print(\"\\n First Complete BikeEase Advertisement:\\n\")\n",
        "print(textwrap.fill(ad_text, width=80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWomd-4JToon",
        "outputId": "1d243b1b-0ae8-44d5-8f11-9ad7a96fb556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " First Complete BikeEase Advertisement:\n",
            "\n",
            "You are a creative advertising copywriter for BikeEase, a bike rental company.\n",
            "Your task is to write ONE complete and persuasive advertisement using the format\n",
            "below:  [Header]: A bold, catchy title [Subheader]: A short supporting phrase\n",
            "[Body]: Describe the bike features, the discount, and the campaign theme [CTA]:\n",
            "A clear call to action [Hashtag]: A relevant hashtag [Footer]: A closing line\n",
            "that reinforces the brand  Use a friendly and adventurous tone. Keep the ad\n",
            "under 150 words. Do not repeat or generate multiple versions. End after the\n",
            "[Footer] section.  - Bike Specifications: mountain & road bikes - Discount /\n",
            "Promotion: 30% off monthly rentals - Campaign Theme: Fall mountain advanture\n",
            "Write the advertisement now. Don't edit it later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = PromptTemplate.from_template(\n",
        "    \"Create a short and engaging advertisement for BikeEase, a bike rental company.\\n\"\n",
        "    \"Use this format:\\n\"\n",
        "    \"Header:\\nSubheader:\\nBody:\\nCTA:\\nHashtag:\\nFooter:\\n\\n\"\n",
        "    \"Details:\\n\"\n",
        "    \"- Bike Specifications: {specs}\\n\"\n",
        "    \"- Discount / Promotion: {discount}\\n\"\n",
        "    \"- Campaign Theme: {theme}\\n\\n\"\n",
        "    \"Use a friendly and adventurous tone. Keep it under 150 words.\\n\\n\"\n",
        "    \"Here is the ad:\"\n",
        ")\n",
        "\n",
        "\n",
        "# Rebuild the chain with the new prompt\n",
        "ad_chain = LLMChain(llm=llm, prompt=template)\n",
        "\n",
        "# Generate the ad\n",
        "response = ad_chain.invoke({\n",
        "    \"specs\": specs_input,\n",
        "    \"discount\": discount_input,\n",
        "    \"theme\": theme_input\n",
        "})\n",
        "\n",
        "# Display the result\n",
        "ad_text = response.get(\"text\", \"\")\n",
        "print(\"\\n First Complete BikeEase Advertisement:\\n\")\n",
        "print(ad_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eew7wOu-a1pU",
        "outputId": "89443a95-0dbd-4e6f-f59e-fb69e55315ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " First Complete BikeEase Advertisement:\n",
            "\n",
            "Create a short and engaging advertisement for BikeEase, a bike rental company.\n",
            "Use this format:\n",
            "Header:\n",
            "Subheader:\n",
            "Body:\n",
            "CTA:\n",
            "Hashtag:\n",
            "Footer:\n",
            "\n",
            "Details:\n",
            "- Bike Specifications: mountain & road bikes\n",
            "- Discount / Promotion: 30% off monthly rentals\n",
            "- Campaign Theme: Fall mountain advanture\n",
            "\n",
            "Use a friendly and adventurous tone. Keep it under 150 words.\n",
            "\n",
            "Here is the ad:\n",
            "\n",
            "[Company Logo]\n",
            "Get your fall adventure started with our [Bike Name], mountain or road biking experience! Our professional staff will help you find the perfect ride for your level of skill. Our equipment includes high quality mountain and road bicycles that are safe and reliable to use on any terrain. Join us as we explore the beauty of nature's best treasures in your own backyard! Book now at www.bikerate.com/bikeease\n",
            "#falladventures #mountainbikerepair #roadcycling @bikerate.com\n",
            "📷 (Image Link)\n",
            "⌚️(Time Stamp)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4"
      ],
      "metadata": {
        "id": "ZEWMzYDVUNTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4 Overview - Evaluation and Optimization\n",
        "\n",
        "In this section, I evaluate the quality, relevance, and persuasiveness of the generated ads. I'll explore prompt tuning, scoring heuristics, and prepare for model comparisons to identify the most effective LLM for BikeEase's marketing use case."
      ],
      "metadata": {
        "id": "8TAQVgipUrTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Strategy\n",
        "\n",
        "I’ll assess generated ads based on:\n",
        "- Structure completeness (Header, Subheader, Body, CTA, Hashtag, Footer)\n",
        "- Relevance to input specs, discount, and theme\n",
        "- Persuasiveness and clarity of language\n",
        "- Brand tone consistency\n",
        "\n",
        "I'll also experiment with prompt variations and compare outputs.\n"
      ],
      "metadata": {
        "id": "Gcpp--shUweD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Define evaluation checklist\n",
        "\n",
        "def evaluate_ad(ad_text, specs, discount, theme):\n",
        "    score = 0\n",
        "    feedback = []\n",
        "\n",
        "    # Check for required sections\n",
        "    required_sections = [\"Header\", \"Subheader\", \"Body\", \"CTA\", \"Hashtag\", \"Footer\"]\n",
        "    for section in required_sections:\n",
        "        if f\"[{section}]\" in ad_text or f\"{section}:\" in ad_text:\n",
        "            score += 1\n",
        "        else:\n",
        "            feedback.append(f\"Missing section: {section}\")\n",
        "\n",
        "    # Check relevance\n",
        "    if specs.lower() in ad_text.lower():\n",
        "        score += 1\n",
        "    else:\n",
        "        feedback.append(\"Specs not clearly reflected.\")\n",
        "\n",
        "    if discount.lower() in ad_text.lower():\n",
        "        score += 1\n",
        "    else:\n",
        "        feedback.append(\"Discount not clearly reflected.\")\n",
        "\n",
        "    if theme.lower() in ad_text.lower():\n",
        "        score += 1\n",
        "    else:\n",
        "        feedback.append(\"Theme not clearly reflected.\")\n",
        "\n",
        "    # Final score out of 9\n",
        "    return score, feedback"
      ],
      "metadata": {
        "id": "p_5UPX0zVLKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Evaluation\n",
        "I’ll now evaluate the ad generated earlier using our checklist. This helps us identify areas for prompt tuning or model refinement."
      ],
      "metadata": {
        "id": "4pQkEzCtVWFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluate previous output\n",
        "ad_text = response.get(\"text\", \"\")\n",
        "if isinstance(ad_text, str) and ad_text.strip():\n",
        "    score, feedback = evaluate_ad(ad_text, specs_input, discount_input, theme_input)\n",
        "    print(f\"Evaluation Score: {score}/9\")\n",
        "    print(\"Feedback:\")\n",
        "    for f in feedback:\n",
        "        print(\"-\", f)\n",
        "else:\n",
        "    print(\"No valid ad text found for evaluation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwQwTSDGePOQ",
        "outputId": "a206d7df-c065-42bf-c5c6-88c9b3216e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Score: 9/9\n",
            "Feedback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Tuning\n",
        "\n",
        "To improve ad quality, I can adjust the prompt instructions. For example:\n",
        "- Emphasize emotional appeal\n",
        "- Add constraints like word count or tone\n",
        "- Include examples of successful ads"
      ],
      "metadata": {
        "id": "6gPdjAzxVy2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Revised prompt template\n",
        "\n",
        "\n",
        "revised_system_msg = (\n",
        "    \"You are a creative marketing copywriter for BikeEase.\\n\"\n",
        "    \"Your goal is to write a persuasive, emotionally engaging ad that highlights:\\n\"\n",
        "    \"- Bike features\\n- Promotional offer\\n- Campaign theme\\n\"\n",
        "    \"Use a friendly and adventurous tone. Keep it under 150 words.\\n\"\n",
        "    \"Return the ad in this format:\\n[Header]\\n[Subheader]\\n[Body]\\n[CTA]\\n[Hashtag]\\n[Footer]\"\n",
        ")\n",
        "\n",
        "revised_template = PromptTemplate.from_template(\n",
        "    \"{system_msg}\\n\\n\"\n",
        "    \"- Bike Specifications: {specs}\\n\"\n",
        "    \"- Discount / Promotion: {discount}\\n\"\n",
        "    \"- Campaign Theme: {theme}\\n\\n\"\n",
        "    \"Write the advertisement now.\"\n",
        ")\n",
        "\n",
        "revised_chain = LLMChain(llm=llm, prompt=revised_template)\n",
        "\n",
        "revised_response = revised_chain.run({\n",
        "    \"system_msg\": revised_system_msg,\n",
        "    \"specs\": specs_input,\n",
        "    \"discount\": discount_input,\n",
        "    \"theme\": theme_input\n",
        "})\n",
        "\n",
        "print(\"\\n--- Revised Advertisement ---\\n\")\n",
        "print(textwrap.fill(revised_response, width=80))\n",
        "print(\"\\n------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmJLB35fWHgc",
        "outputId": "9eac6c32-dfaa-45d7-c41c-ec5818938ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Revised Advertisement ---\n",
            "\n",
            "You are a creative marketing copywriter for BikeEase. Your goal is to write a\n",
            "persuasive, emotionally engaging ad that highlights: - Bike features -\n",
            "Promotional offer - Campaign theme Use a friendly and adventurous tone. Keep it\n",
            "under 150 words. Return the ad in this format: [Header] [Subheader] [Body] [CTA]\n",
            "[Hashtag] [Footer]  - Bike Specifications: mountain & road bikes - Discount /\n",
            "Promotion: 30% off monthly rentals - Campaign Theme: Fall mountain advanture\n",
            "Write the advertisement now.\n",
            "\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps\n",
        "\n",
        "- Compare outputs from different models (e.g., TinyLlama vs. Flan-T5 or Falcon)\n",
        "- Add human feedback loop or scoring rubric\n"
      ],
      "metadata": {
        "id": "FF-6jxKwWSOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other models options to test"
      ],
      "metadata": {
        "id": "NzKaEov-KD6b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DwkNxL7H8_9"
      },
      "source": [
        "## google/flan-t5-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sCMpACpIAsl"
      },
      "outputs": [],
      "source": [
        "# MODEL_NAME = \"google/flan-t5-base\"\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# # ATENÇÃO! dif class\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "#     MODEL_NAME,\n",
        "#     torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        "# ).to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY9-quw5IBPx"
      },
      "source": [
        "## google/flan-t5-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K85Q9XQlID1e"
      },
      "outputs": [],
      "source": [
        "# MODEL_NAME = \"google/flan-t5-large\"\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# # ATENÇÃO! dif class\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "#     MODEL_NAME,\n",
        "#     torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        "# ).to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkPL0KZMIFTQ"
      },
      "source": [
        "## facebook/opt-1.3b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgxispLLIGwR"
      },
      "outputs": [],
      "source": [
        "# MODEL_NAME = \"facebook/opt-1.3b\"\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     MODEL_NAME,\n",
        "#     torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        "# ).to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZmlrOPIH3H"
      },
      "source": [
        "## tiiuae/falcon-rw-1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxPshCO9IKEM"
      },
      "outputs": [],
      "source": [
        "# MODEL_NAME = \"tiiuae/falcon-rw-1b\"\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     MODEL_NAME,\n",
        "#     torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "#     trust_remote_code=True # Importante for that model\n",
        "# ).to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQkO88JYIKiG"
      },
      "source": [
        "## microsoft/phi-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx8ltemzIMxI"
      },
      "outputs": [],
      "source": [
        "# MODEL_NAME = \"microsoft/phi-2\"\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     MODEL_NAME,\n",
        "#     torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "#     trust_remote_code=True # Importante for that model\n",
        "# ).to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Report"
      ],
      "metadata": {
        "id": "991UtftdgDYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "\n",
        "This project was designed to build a modular, generative AI pipeline that creates persuasive advertisements for BikeEase, a fictional bike rental company. The goal was to integrate prompt engineering, model tuning, and evaluation logic into a cohesive system that could generate structured, brand-aligned marketing content.\n",
        "\n",
        "---\n",
        "\n",
        "## Technologies & Tools Used\n",
        "\n",
        "- **LangChain**: For chaining prompts and managing structured input/output.\n",
        "- **Hugging Face Transformers**: To load and run local language models (TinyLlama, etc.).\n",
        "- **Python**: Core scripting language for logic, evaluation, and orchestration.\n",
        "- **Regex & Textwrap**: For post-processing and formatting output.\n",
        "- **Custom Evaluation Function**: To score generated ads based on structure and relevance.\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Components & What I Learned\n",
        "\n",
        "### 1. **Prompt Engineering**\n",
        "- I learned how to design prompts that guide the model toward structured output.\n",
        "- I experimented with different formats (`[Header]`, `Header:`) and tone instructions.\n",
        "- I discovered that smaller models often echo instructions or ignore formatting unless phrased carefully.\n",
        "\n",
        "### 2. **Model Invocation**\n",
        "- I used `.invoke()` instead of `.run()` to align with LangChain’s updated API.\n",
        "- I learned how to pass structured input (specs, discount, theme) into the chain.\n",
        "- I tuned generation parameters like `max_new_tokens`, `temperature`, and `repetition_penalty` to balance creativity and control.\n",
        "\n",
        "### 3. **Output Handling**\n",
        "- I used `textwrap` to format long outputs for readability.\n",
        "- I implemented fallback logic to handle cases where the model returned a dictionary instead of a string.\n",
        "- I added regex-based extraction to isolate complete ad blocks when needed.\n",
        "\n",
        "### 4. **Evaluation Logic**\n",
        "- I built a scoring system that checks for six required sections and three content relevance points.\n",
        "- I learned how to validate model output programmatically and give actionable feedback.\n",
        "- I added flexibility to support both `[Header]` and `Header:` formats.\n",
        "\n",
        "### 5. **Debugging & Iteration**\n",
        "- I encountered and resolved common errors like `AttributeError` from type mismatches.\n",
        "- I learned how to interpret model behavior (e.g., prompt echoing) and adjust accordingly.\n",
        "- I iterated on prompt phrasing to improve section adherence and reduce placeholder usage.\n",
        "\n",
        "---\n",
        "\n",
        "## Observations & Insights\n",
        "\n",
        "- **Smaller models** require simpler, more natural prompts — overly rigid instructions can cause them to echo or stall.\n",
        "- **Prompt phrasing** matters more than I expected. Even small changes like “Here is the ad:” can shift model behavior.\n",
        "- **Evaluation functions** are essential for scaling generative systems — they help automate quality control and guide improvements.\n",
        "- **Modularity** is key. By separating generation, formatting, and evaluation, I created a pipeline that’s easy to extend or swap components.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Outcome\n",
        "\n",
        "- I successfully generated structured advertisements that reflect brand tone, product specs, and promotional offers.\n",
        "- I built a reusable system that can be adapted for other brands, campaigns, or languages.\n",
        "- I gained hands-on experience with prompt engineering, model tuning, and generative evaluation — all critical skills for real-world AI/ML applications.\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Add tone/style evaluation (e.g., adventurous, friendly, persuasive).\n",
        "- Build a Gradio or Streamlit interface for non-technical users.\n",
        "- Test with larger models (e.g., `phi-2`, `flan-t5-base`) for improved formatting and creativity.\n",
        "- Expand evaluation to include grammar, clarity, and emotional appeal.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DeqgVQuBgHyA"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}